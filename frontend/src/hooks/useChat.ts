import { useState, useCallback } from 'react'

export interface ChatMessage {
  role: 'user' | 'assistant'
  content: string
  timestamp?: Date
}

interface ChatRequest {
  messages: ChatMessage[]
  model?: string
}

interface ChatResponse {
  message: ChatMessage
  usage?: {
    promptTokens: number
    completionTokens: number
    totalTokens: number
  }
}

export interface TokenUsageCallback {
  (usage: { promptTokens: number; completionTokens: number; totalTokens: number } | null | undefined): void
}

interface UseChatOptions {
  onTokenUsage?: TokenUsageCallback
  model?: string
}

export const useChat = (options?: UseChatOptions) => {
  const [messages, setMessages] = useState<ChatMessage[]>([])
  const [isLoading, setIsLoading] = useState(false)

  const sendMessage = useCallback(async (content: string, files?: File[]) => {
    if (!content.trim() && (!files || files.length === 0)) return

    const userMessage: ChatMessage = {
      role: 'user',
      content: content.trim(),
      timestamp: new Date(),
    }

    // Add user message immediately and capture updated messages
    let updatedMessages: ChatMessage[] = []
    setMessages((prev) => {
      updatedMessages = [...prev, userMessage]
      return updatedMessages
    })
    setIsLoading(true)

    try {
      let response: Response

      // Si hay archivos, enviar como FormData
      if (files && files.length > 0) {
        const formData = new FormData()
        formData.append('model', options?.model || 'gpt-4o-mini')
        formData.append('messages', JSON.stringify(updatedMessages.map(({ role, content }) => ({ role, content }))))
        
        files.forEach((file) => {
          formData.append(`files`, file)
        })

        response = await fetch('/api/chat', {
          method: 'POST',
          body: formData,
        })
      } else {
        // Sin archivos, enviar JSON normal
        const requestBody: ChatRequest = {
          messages: updatedMessages.map(({ role, content }) => ({
            role,
            content,
          })),
          model: options?.model,
        }

        response = await fetch('/api/chat', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(requestBody),
        })
      }

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        const errorMsg = errorData.error || errorData.message || 'Error al comunicarse con el servidor'
        throw new Error(errorMsg)
      }

      const data: ChatResponse = await response.json()
      const assistantMessage: ChatMessage = {
        ...data.message,
        timestamp: new Date(),
      }

      setMessages((prev) => [...prev, assistantMessage])

      // Notify about token usage
      if (options?.onTokenUsage && data.usage) {
        console.log('Token usage received:', data.usage)
        options.onTokenUsage(data.usage)
      } else {
        console.log('No token usage data or callback:', { hasCallback: !!options?.onTokenUsage, hasUsage: !!data.usage, usage: data.usage })
      }
    } catch (error) {
      console.error('Error sending message:', error)
      let errorContent = 'Lo siento, ocurriÃ³ un error. Por favor intenta de nuevo.'
      
      if (error instanceof Error) {
        if (error.message.includes('API key')) {
          errorContent = 'ğŸ”‘ Error: API key no configurada. Por favor configura tu OpenAI API key en el backend. Consulta CONFIGURAR_API_KEY.md para mÃ¡s informaciÃ³n.'
        } else if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
          errorContent = 'ğŸŒ Error de conexiÃ³n: No se pudo conectar al servidor. AsegÃºrate de que el backend estÃ© ejecutÃ¡ndose.'
        } else {
          errorContent = `âŒ Error: ${error.message}`
        }
      }
      
      const errorMessage: ChatMessage = {
        role: 'assistant',
        content: errorContent,
        timestamp: new Date(),
      }
      setMessages((prev) => [...prev, errorMessage])
    } finally {
      setIsLoading(false)
    }
  }, [options?.model, options?.onTokenUsage])

  return {
    messages,
    sendMessage,
    isLoading,
    setMessages,
    clearMessages: () => setMessages([]),
  }
}


